from fastapi import FastAPI, Body, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import base64
import io
import os
from PIL import Image
import google.generativeai as genai
from dotenv import load_dotenv

# === 1. å®‰å…¨åŠ è½½ç¯å¢ƒå˜é‡ ===
load_dotenv() # è¿™ä¼šè‡ªåŠ¨è¯»å–åŒç›®å½•ä¸‹çš„ .env æ–‡ä»¶
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    print("âŒ è­¦å‘Š: æœªæ‰¾åˆ° GEMINI_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")

# === 2. é…ç½® Gemini 2.5 ===
genai.configure(api_key=API_KEY)

# ğŸ”¥ ä½¿ç”¨æœ€æ–°çš„ 2.5 Flash Image æ¨¡å‹
# è¿™ä¸ªæ¨¡å‹åŸç”Ÿæ”¯æŒï¼š[å›¾+æ–‡] è¾“å…¥ -> [å›¾+æ–‡] è¾“å‡º
# ä¹Ÿå°±æ˜¯å®ƒèƒ½ç›´æ¥å¬æ‡‚ "æŠŠèƒŒæ™¯æ‰£æ‰" å¹¶åå‡ºä¸€å¼ é€æ˜åº•çš„å›¾ï¼Œä¸éœ€è¦å¤–æŒ‚
model = genai.GenerativeModel('gemini-2.5-flash-image')

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def read_root():
    return {"message": "âš¡ï¸ Gemini 2.5 Flash Image å¼•æ“å·²å°±ç»ª"}

@app.post("/run_node")
async def run_node(
    prompt: str = Form(...), 
    image: UploadFile = File(None), 
    is_image_mode: str = Form("false")
):
    print(f"ğŸ§  [Gemini 2.5] æ”¶åˆ°ä»»åŠ¡: {prompt[:30]}...")

    try:
        # 1. å¤„ç†è¾“å…¥å›¾ç‰‡
        pil_image = None
        if image:
            content = await image.read()
            pil_image = Image.open(io.BytesIO(content))
            print("ğŸ“¸ å›¾ç‰‡å·²åŠ è½½")
        
        # 2. æ„é€  2.5 å¤šæ¨¡æ€è¯·æ±‚
        # ç°åœ¨çš„ prompt å¯ä»¥éå¸¸ç›´æ¥ï¼Œæ¯”å¦‚ "Remove background" æˆ–è€… "Change the cat to a dog"
        inputs = [prompt]
        if pil_image:
            inputs.append(pil_image)
            
        print("ğŸš€ å‘é€ç»™ Gemini 2.5 Flash Image...")
        
        # 3. è°ƒç”¨ç”Ÿæˆ (æ³¨æ„ï¼š2.5 çš„ output å¯èƒ½åŒ…å« image)
        response = model.generate_content(inputs)
        
        # 4. è§£æç»“æœ (æ··åˆæ¨¡æ€è§£æ)
        # Gemini 2.5 Flash Image è¿”å›çš„ part å¯èƒ½åŒ…å« text ä¹Ÿå¯èƒ½åŒ…å« inline_data (å›¾ç‰‡)
        
        output_text = ""
        output_image_b64 = None
        
        # éå†è¿”å›çš„æ¯ä¸€ä¸ªéƒ¨åˆ†
        if response.parts:
            for part in response.parts:
                if part.text:
                    output_text += part.text
                if part.inline_data:
                    # ğŸ”¥ æŠ“åˆ°äº†ï¼æ¨¡å‹ç›´æ¥ç”Ÿæˆäº†å›¾ç‰‡ï¼
                    print("ğŸ¨ æ¨¡å‹è¿”å›äº†åŸç”Ÿå›¾ç‰‡æ•°æ®")
                    # inline_data é€šå¸¸æ˜¯ raw bytesï¼Œæˆ‘ä»¬éœ€è¦è½¬æˆ base64 ä¼ ç»™å‰ç«¯
                    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ SDK è¿”å›çš„æ˜¯ bytes æˆ–è€…åŒ…å« data å±æ€§çš„å¯¹è±¡
                    # å…·ä½“å–å†³äº google-generativeai çš„ç‰ˆæœ¬ï¼Œé€šå¸¸æ˜¯ part.inline_data.data
                    img_data = part.inline_data.data
                    output_image_b64 = base64.b64encode(img_data).decode('utf-8')

        # 5. æ„é€ è¿”å›ç»™å‰ç«¯çš„æ•°æ®
        # å¦‚æœæ¨¡å‹ç”Ÿæˆäº†å›¾ï¼Œä¼˜å…ˆè¿”å›å›¾ï¼›å¦åˆ™è¿”å›å­—
        if output_image_b64:
            print("âœ… è¿”å›ç”Ÿæˆå›¾")
            return {
                "status": "success", 
                "type": "image", 
                "output": output_image_b64
            }
        else:
            print(f"âœ… è¿”å›æ–‡æœ¬: {output_text[:20]}...")
            return {
                "status": "success", 
                "type": "text", 
                "output": output_text if output_text else "æ¨¡å‹å¤„ç†å®Œæˆï¼Œä½†æœªè¿”å›å†…å®¹ã€‚"
            }

    except Exception as e:
        print(f"âŒ 2.5 æŠ¥é”™: {e}")
        # å®¹é”™ï¼šå¦‚æœ 2.5 Image æŒ‚äº†æˆ–è€… Key ä¸å¯¹ï¼Œè¿”å›ä¸€ä¸ªé”™è¯¯æç¤º
        return {"status": "error", "message": str(e)}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)